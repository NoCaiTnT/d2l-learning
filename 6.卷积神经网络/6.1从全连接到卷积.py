# 卷积
# https://www.bilibili.com/video/BV1VV411478E/?from=search&seid=1725700777641154181&vd_source=0962321c39a062f02de9dc156fac6c91
# ∫ f(x)g(t-x)dx
# 一个系统, 输入不稳定, 输出稳定, 用卷积求系统存量
#   不稳定输入代表人吃食物吃的量不稳定, 稳定的输出代表消化食物的能力是稳定不变的, 通过卷积可以系统的存量代表求出胃里剩余的食物
#   相当于在x时刻吃的饭, 对t时刻肚子里剩余食物的影响
#   扩展为其他时刻吃的饭对t时刻的影响
#   将时间可以扩展为距离
#   在图像上: 扩展为其他像素 根据距离 对某一像素的影响 -> 自己对周围像素点的试探(过滤器)
#   即 对于3*3的卷积核, 作用是求得 卷积核外圈所有像素 对 中心像素的影响
#   图像是函数f, 卷积核旋转180°是函数g(规定了如何影响)
#   一般省略旋转的过程(卷积是交叉相关的旋转)
#   实际上用的是交叉相关
# 卷积神经网络
#   提取局部特征(通过卷积)
# 卷积的三种含义
#   不稳定输入, 稳定输出, 求系统存量
#   图像处理, 周围像素点如何产生影响
#   过滤器, 一个像素点如何试探周围像素点, 如何筛选图像的特征

# 两个原则
#   平移不变性(translation invariance): 不管检测对象出现在图像中的哪个位置, 神经网络的前面几层应该对相同的图像区域具有相似的反应, 即为"平移不变性"
#   局部性(locality): 神经网络的前面几层应该只探索输入图像中的局部区域, 而不过度在意图像中相隔较远区域的关系, 这就是"局部性"原则, 最终, 可以聚合这些局部特征, 以在整个图像级别进行预测
# 重新考察全连接层
#   将输入和输出变为2D矩阵(宽度, 高度) 输入n, 输出m -> 输入(k,l), 输出(i, j)
#   将权重变形为4D张量(h, w)到(h', w')   权重(m, n) - > (i, j, k, l)
#       h_i,j = \sum_{k,l} w_i,j,k,l x_k,l = \sum_{a,b} v_i,j,a,b x_{i+a, j+b}
#   V是W的重新索引v_i,j,a,b = w_i,j,i+a,j+b
# 原则1 平移不变形
#   x的平移导致h的平移, 当x的i, j发生改变时, v也跟着改变
#   v不应该依赖于i, j
#   这里我的理解是, 图像中有一只猫, 网络识别该猫的权重 不应该随着 猫的位置的改变而改变(即不管猫是在图像的左上角, 右下角, 都应该用一样的权重识别出来, 因为猫的样子没有改变)
#   解决方案: v_i,j,a,b = v_a,b
#       h_i,j = \sum_{a,b} v_a,b x_{i+a,j+b}
#   即2维的交叉相关
# 原则2 局部性
#   当评估h_i,j时, 不应该用远离x_i,j的参数, 应该只考虑它的周围的元素对它的影响
#   解决方案: 当|a|, |b| > Δ 时, 使得v_a,b = 0
#       h_i,j = \sum_{a=-Δ}^{Δ} \sum_{b=-Δ}^{Δ} v_a,b x_{i+a,j+b}
# 总结
#   对全连接层使用平移不变形和局部性得到卷积层

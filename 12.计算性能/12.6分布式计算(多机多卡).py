# 分布式计算(数据并行)(多机多卡)
#   样本: 数据放在分布式文件系统上
#   有多个worker: 每个机器被称为worker, 每个worker有多个显卡
#   有多个参数服务器: 每个参数服务器存放模型的部分参数
#   步骤:
#       每个worker通过网络读取数据
#       workers和参数服务器之间通过网络进行发送
# GPU机器架构
#   一台机器上GPU之间的通讯, 通过PCIe, 每个GPU都连接到PCIe交换机上(速度快)
#   GPU与CPU之间的通讯, 需要通过PCIe交换机, GPU <-> PCIe交换机 <-> CPU(速度一般)
#   机器之间的通讯, 需要通过交换机(速度慢)
#   因此尽量本地GPU之间进行通讯
# 计算一个小批量(数据并行)(2workers, 2GPU/worker, 样本为100)
#   每个计算服务器worker读取小批量样本中的一块(50样本/worker)
#   进一步将数据切分到每个GPU上(25样本/GPU)
#   每个worker从参数服务器获取模型参数(每个worker都拷贝一份)
#   复制参数到每个GPU上(每个worker给GPU进行复制)
#   每个GPU计算梯度
#   将所有GPU上的梯度求和(在worker中讲梯度相加)
#   将梯度传回服务器(每个worker传一个梯度)
#   每个服务器对梯度求和, 并更新参数
#   循环迭代
# 同步SGD
#   这里每个worker都是同步计算一个批量, 称为同步SGD
#   假设有n个GPU, 每个GPU每次处理b个样本, 那么同步SGD等价于在单GPU运行批量大小为nb的SGD
#   在理想情况下, n个GPU可以得到相对于单GPU的n倍加速
# 性能
#   t1 = 单GPU上计算b个样本梯度的时间
#   假设有m个参数, 一个worker每次发送和接收m个参数, 梯度
#       t2 = 发送和接收所用时间
#   每个批量的计算时间为max(t1, t2)(流水线)
#       问题: t2 > t1, 即计算时间被收发时间阻塞, 会导致GPU一定时间空闲
#       选取足够大的b使得t1 > t2 (参数大小是不变的, 因此增加b不会导致t2的增加)
#       增加b或n导致更大的批量大小, 导致需要更多计算来得到给定的模型精度(收敛变慢)
# 性能的权衡
#   系统性能: 每个epoch的时间, 随批量大小的增加而增加(批量越大, 训练越快, epoch时间越小)
#   训练有效性: 需要多少个epoch, 随批量大小的增加而减少(批量越大, 收敛越慢, 所需epoch越多)
#   理想批量大小: 二者的交点(需要增加批量大小, 但不要增加太多)
# 实践时的建议
#   使用一个大的数据集(类别也要多一些)
#   需要好的GPU <-> GPU(主板)和机器 <-> 机器(交换机/网线)的带宽
#   高效的数据读取和预处理
#   模型需要有好的计算(FLOP)通讯(model size)比: Inception > ResNet > AlexNet
#   使用足够大的批量大小来得到好的系统性能
#   使用高效的优化算法来对应批量大小
# 总结
#   分布式同步数据并行是多GPU数据并行在多机器上的拓展
#   网络通讯通常是瓶颈
#   需要注意使用特别大的批量大小时的收敛效率
#   更复杂的分布式有异步、模型并行
